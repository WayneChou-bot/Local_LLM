import streamlit as st
import os
from langchain_community.document_loaders import PyMuPDFLoader, TextLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from dotenv import load_dotenv

load_dotenv()

VECTOR_DIR = "vectorstore"
SOURCE_DIR = "source_documents"

def load_single_document(filepath):
    if filepath.endswith(".pdf"):
        loader = PyMuPDFLoader(filepath)
    elif filepath.endswith(".txt"):
        loader = TextLoader(filepath)
    elif filepath.endswith(".docx"):
        loader = Docx2txtLoader(filepath)
    else:
        raise ValueError("Unsupported file type")
    return loader.load()

def ingest_all():
    st.info("ğŸ“„ é–‹å§‹è™•ç†æ–‡ä»¶è³‡æ–™å¤¾...")
    
    if not os.path.exists(SOURCE_DIR):
        st.error("âŒ æ‰¾ä¸åˆ°è³‡æ–™å¤¾ source_documents")
        return

    documents = []
    for filename in os.listdir(SOURCE_DIR):
        filepath = os.path.join(SOURCE_DIR, filename)
        if filename.lower().endswith((".pdf", ".txt", ".docx")):
            st.write(f"ğŸ“‚ è¼‰å…¥ï¼š{filename}")
            documents.extend(load_single_document(filepath))

    if not documents:
        st.warning("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å¯è™•ç†æ–‡ä»¶ã€‚")
        return

    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = text_splitter.split_documents(documents)

    embeddings = OpenAIEmbeddings()

    if os.path.exists(f"{VECTOR_DIR}/index.faiss"):
        db = FAISS.load_local(VECTOR_DIR, embeddings, allow_dangerous_deserialization=True)
        db.add_documents(texts)
        st.success(f"âœ… å·²æ–°å¢ {len(texts)} ç­†æ®µè½åˆ°ç¾æœ‰å‘é‡è³‡æ–™åº«ã€‚")
    else:
        db = FAISS.from_documents(texts, embeddings)
        db.save_local(VECTOR_DIR)
        st.success(f"âœ… å‘é‡è³‡æ–™åº«å»ºç«‹å®Œæˆï¼Œå…± {len(texts)} ç­†æ®µè½ã€‚")

# ------------------------
# Streamlit UI
# ------------------------
st.set_page_config(page_title="æ–‡ä»¶å‘é‡åŒ–", layout="centered")
st.title("ğŸ“š æ–‡ä»¶å‘é‡åŒ–å·¥å…·")

st.markdown("è«‹ä¸Šå‚³æ–‡ä»¶è‡³ `source_documents/` è³‡æ–™å¤¾å¾Œï¼Œé»æ“Šä¸‹æ–¹æŒ‰éˆ•é€²è¡Œè™•ç†ã€‚")

if st.button("ğŸš€ ä¸€éµåŸ·è¡Œ ingest"):
    ingest_all()

# é¡¯ç¤ºç•¶å‰å·²æœ‰çš„æ–‡ä»¶
if os.path.exists(SOURCE_DIR):
    files = os.listdir(SOURCE_DIR)
    if files:
        st.markdown("### ğŸ“„ ç›®å‰è³‡æ–™å¤¾å…§æª”æ¡ˆï¼š")
        for file in files:
            st.write(f"â€¢ {file}")
    else:
        st.info("ç›®å‰å°šæœªä¸Šå‚³ä»»ä½•æ–‡ä»¶ã€‚")
else:
    os.makedirs(SOURCE_DIR)
    st.info("å·²è‡ªå‹•å»ºç«‹ source_documents è³‡æ–™å¤¾ï¼Œè«‹æ”¾å…¥ä½ çš„æ–‡ä»¶ã€‚")
