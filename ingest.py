# ingest.pyï¼ˆå·²æ›´æ–°æ”¯æ´ OCR PDFã€åŠ å…¥ç­†æ•¸æç¤ºï¼‰
import os
from langchain_community.document_loaders import PyMuPDFLoader, TextLoader, Docx2txtLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from dotenv import load_dotenv

load_dotenv()

# åœ¨ ingest.py çš„ load_single_document å‡½æ•¸ä¸­æ·»åŠ 
def load_single_document(filepath):
    if filepath.endswith(".pdf"):
        loader = PyMuPDFLoader(filepath)
    elif filepath.endswith(".txt"):
        loader = TextLoader(filepath)
    elif filepath.endswith(".docx"):
        loader = Docx2txtLoader(filepath)
    else:
        raise ValueError("Unsupported file type")
    
    docs = loader.load()
    # æ¸…ç†metadataä¸­çš„è·¯å¾‘
    for doc in docs:
        if 'source' in doc.metadata:
            doc.metadata['source'] = os.path.basename(doc.metadata['source'])
    return docs

def ingest_file(filepath):
    docs = load_single_document(filepath)
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = text_splitter.split_documents(docs)
    embeddings = OpenAIEmbeddings()
    if os.path.exists("vectorstore/index.faiss"):
        db = FAISS.load_local("vectorstore", embeddings, allow_dangerous_deserialization=True)
        db.add_documents(texts)
    else:
        db = FAISS.from_documents(texts, embeddings)
    db.save_local("vectorstore")
    print(f"âœ… å‘é‡åŒ–å®Œæˆï¼š{filepath}ï¼Œæ®µè½æ•¸ï¼š{len(texts)}")

def ingest_all():
    print("ğŸ“„ æƒæè³‡æ–™å¤¾ï¼šsource_documents")
    source_dir = "source_documents"
    documents = []
    for filename in os.listdir(source_dir):
        filepath = os.path.join(source_dir, filename)
        if filename.endswith((".pdf", ".txt", ".docx")):
            documents.extend(load_single_document(filepath))
    if not documents:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å¯è™•ç†æ–‡ä»¶ã€‚")
        return
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    texts = text_splitter.split_documents(documents)
    embeddings = OpenAIEmbeddings()
    db = FAISS.from_documents(texts, embeddings)
    db.save_local("vectorstore")
    print(f"âœ… å‘é‡åŒ–å®Œæˆï¼Œå…±è™•ç†æ®µè½æ•¸ï¼š{len(texts)}")

if __name__ == "__main__":
    ingest_all()

# run_ingest.batï¼ˆWindows ç’°å¢ƒä¸€éµåŸ·è¡Œè…³æœ¬ï¼‰
# è«‹å°‡ä»¥ä¸‹å…§å®¹å¦å­˜ç‚º run_ingest.bat
# ===============================
# @echo off
# echo æ­£åœ¨å•Ÿå‹•æ–‡ä»¶å‘é‡åŒ–...
# call conda activate your_env_name  || echo (å¯æ‰‹å‹•åˆ‡æ›ç’°å¢ƒ)
# python ingest.py
# pause
# ===============================

# Linux / macOS å¯ç”¨ bash:
# chmod +x run_ingest.sh
# ./run_ingest.sh

# run_ingest.sh
# ===============================
# #!/bin/bash
# echo "ğŸ” æ­£åœ¨å‘é‡åŒ–æ‰€æœ‰æ–‡ä»¶..."
# python ingest.py
# ===============================
